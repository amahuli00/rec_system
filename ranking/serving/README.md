# Ranking Serving Module

Real-time inference for the ranking model.

## Overview

This module provides the `RankerService` class that scores and ranks candidate items for a user. It orchestrates:

1. **Feature building** - Builds features for user + candidate movies using pre-computed statistics
2. **Model inference** - Runs XGBoost prediction on the feature matrix
3. **Result ranking** - Returns sorted results by predicted score

## Quick Start

```python
from ranking.serving import RankerService

# Initialize service (loads model and data once)
service = RankerService()

# Rank candidates for a user
results = service.rank(user_id=1088, candidate_ids=[1, 50, 100, 200])

for item in results:
    print(f"Rank {item.rank}: Movie {item.movie_id} (score: {item.predicted_score:.3f})")
```

Output:
```
Rank 1: Movie 50 (score: 4.270)
Rank 2: Movie 1 (score: 3.973)
Rank 3: Movie 100 (score: 3.583)
Rank 4: Movie 200 (score: 2.920)
```

## Components

### RankerService

Main entry point for ranking inference.

```python
class RankerService:
    def __init__(self, model_name: str = "xgboost_tuned"):
        """Initialize with specified model."""

    def rank(self, user_id: int, candidate_ids: List[int]) -> List[RankedItem]:
        """Score and rank candidates, returning sorted results."""

    def score(self, user_id: int, candidate_ids: List[int]) -> List[float]:
        """Get raw scores without ranking (lighter weight)."""
```

### RankedItem

Dataclass for ranked results:

```python
@dataclass
class RankedItem:
    movie_id: int
    predicted_score: float
    rank: int  # 1 = best
```

### ServingFeatureBuilder

Internal class that builds features at inference time. Uses pre-computed statistics for fast lookup.

## Data Dependencies

The serving module requires these pre-computed files:

| File | Description | Generated By |
|------|-------------|--------------|
| `ranking/features/user_stats.parquet` | User aggregation features | `--save-serving-data` flag |
| `ranking/features/movie_stats.parquet` | Movie aggregation features | `--save-serving-data` flag |
| `ranking/features/feature_metadata.json` | Cold-start defaults | Feature builder |
| `ranking/models/xgboost_tuned.json` | Trained model | Model trainer |
| `ranking/models/feature_columns.json` | Feature column order | Model trainer |
| `data/splits/users.parquet` | User demographics | Data splits |
| `data/splits/movies.parquet` | Movie metadata + genres | Data splits |

To generate serving data:
```bash
python -m ranking.features.build_features --serving-data-only
```

## Cold-Start Handling

The service handles cold-start scenarios automatically:

- **Unknown users**: Uses global default user statistics from training data
- **Unknown movies**: Uses global default movie statistics, no genre features

```python
# Works for users/movies not in training data
results = service.rank(user_id=999999, candidate_ids=[1, 999999])
```

## Architecture

```
RankerService.rank(user_id, candidate_ids)
    │
    ├─→ ServingFeatureBuilder.build_features()
    │       ├─→ user_stats.parquet lookup (or cold-start default)
    │       ├─→ movie_stats.parquet lookup (or cold-start default)
    │       ├─→ User demographics lookup
    │       ├─→ Movie genre lookup
    │       ├─→ Compute interaction features
    │       └─→ Return DataFrame (N rows × 35 features)
    │
    ├─→ xgb.DMatrix(features)
    ├─→ model.predict() → scores
    │
    └─→ Sort by score → List[RankedItem]
```

## Design Decisions

### Stateful Service
The service loads model and data once at initialization. This is typical for production services where you want fast per-request latency.

### Pre-computed Statistics
User and movie aggregation statistics are pre-computed from training data and stored in parquet files. This ensures:
- Fast lookup at inference time
- Consistency with training features
- No data leakage (stats frozen at training time)

### Feature Consistency
The `ServingFeatureBuilder` mirrors the batch `FeatureBuilder` logic exactly to ensure predictions match between batch and serving inference.

## Performance

Typical latency for ranking 100 candidates: ~5-10ms (after initialization)

Initialization time: ~1-2s (loads model, parquets, builds lookup dicts)
