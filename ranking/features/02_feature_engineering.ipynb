{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking: Feature Engineering\n",
    "\n",
    "**Phase 1: Exploration**\n",
    "\n",
    "This notebook creates features for the GBDT ranking model.\n",
    "\n",
    "## Strategy\n",
    "\n",
    "- **Simple aggregation features first**: User/movie statistics from training data\n",
    "- **Prevent data leakage**: Only use training data for aggregations\n",
    "- **Handle cold-start**: Provide defaults for new users/movies (though minimal with filtered splits)\n",
    "- **Prepare for GBDT**: XGBoost/LightGBM-friendly features\n",
    "\n",
    "## Feature Categories (38 total)\n",
    "\n",
    "1. **User aggregations** (5): rating count, avg, std, min, max\n",
    "2. **Movie aggregations** (5): rating count, avg, std, min, max\n",
    "3. **User-movie interactions** (4): rating diff, normalized counts, activity product\n",
    "4. **Demographics** (3): gender, age, occupation\n",
    "5. **Genres** (18): multi-hot encoding of 18 movie genres\n",
    "6. **Target + IDs** (3): rating, user_id, movie_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport json\n\n# Set display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# Set plotting style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\n# Paths\nDATA_DIR = Path('../../data/splits')\nFEATURES_DIR = Path('.')  # Save features in the same directory as notebook"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits\n",
    "train_ratings = pd.read_parquet(DATA_DIR / 'train_ratings.parquet')\n",
    "val_ratings = pd.read_parquet(DATA_DIR / 'val_ratings.parquet')\n",
    "test_ratings = pd.read_parquet(DATA_DIR / 'test_ratings.parquet')\n",
    "\n",
    "# Load metadata\n",
    "movies = pd.read_parquet(DATA_DIR / 'movies.parquet')\n",
    "users = pd.read_parquet(DATA_DIR / 'users.parquet')\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(f\"Train: {len(train_ratings):,} ratings\")\n",
    "print(f\"Val:   {len(val_ratings):,} ratings\")\n",
    "print(f\"Test:  {len(test_ratings):,} ratings\")\n",
    "print(f\"Movies: {len(movies):,}\")\n",
    "print(f\"Users:  {len(users):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Schema Definition\n",
    "\n",
    "Define exactly which features we'll create and their interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature schema documentation\n",
    "FEATURE_SCHEMA = {\n",
    "    \"user_aggregations\": {\n",
    "        \"user_rating_count\": \"Number of ratings user has given (activity level)\",\n",
    "        \"user_avg_rating\": \"User's average rating (generosity/strictness)\",\n",
    "        \"user_rating_std\": \"Std dev of user's ratings (consistency)\",\n",
    "        \"user_rating_min\": \"Minimum rating given by user\",\n",
    "        \"user_rating_max\": \"Maximum rating given by user\"\n",
    "    },\n",
    "    \"movie_aggregations\": {\n",
    "        \"movie_rating_count\": \"Number of ratings movie received (popularity)\",\n",
    "        \"movie_avg_rating\": \"Movie's average rating (perceived quality)\",\n",
    "        \"movie_rating_std\": \"Std dev of movie ratings (controversy/polarization)\",\n",
    "        \"movie_rating_min\": \"Minimum rating received by movie\",\n",
    "        \"movie_rating_max\": \"Maximum rating received by movie\"\n",
    "    },\n",
    "    \"interactions\": {\n",
    "        \"user_movie_rating_diff\": \"Difference: user_avg - movie_avg\",\n",
    "        \"user_rating_count_norm\": \"Log-transformed user rating count\",\n",
    "        \"movie_rating_count_norm\": \"Log-transformed movie rating count\",\n",
    "        \"user_movie_activity_product\": \"Product of normalized counts\"\n",
    "    },\n",
    "    \"demographics\": {\n",
    "        \"gender\": \"User gender (M=1, F=0)\",\n",
    "        \"age_group\": \"User age group (1, 18, 25, 35, 45, 50, 56)\",\n",
    "        \"occupation\": \"User occupation code (0-20)\"\n",
    "    },\n",
    "    \"genres\": \"18 binary features for movie genres\"\n",
    "}\n",
    "\n",
    "print(\"Feature Schema:\")\n",
    "for category, features in FEATURE_SCHEMA.items():\n",
    "    if isinstance(features, dict):\n",
    "        print(f\"\\n{category}:\")\n",
    "        for name, desc in features.items():\n",
    "            print(f\"  {name}: {desc}\")\n",
    "    else:\n",
    "        print(f\"\\n{category}: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Aggregation Features\n",
    "\n",
    "**Critical**: Computed ONLY from training data to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute user statistics from TRAIN ONLY\n",
    "user_stats = train_ratings.groupby('user_id')['rating'].agg([\n",
    "    ('user_rating_count', 'count'),\n",
    "    ('user_avg_rating', 'mean'),\n",
    "    ('user_rating_std', 'std'),\n",
    "    ('user_rating_min', 'min'),\n",
    "    ('user_rating_max', 'max')\n",
    "]).reset_index()\n",
    "\n",
    "# Fill NaN std (happens when user has only 1 rating)\n",
    "user_stats['user_rating_std'] = user_stats['user_rating_std'].fillna(0)\n",
    "\n",
    "print(f\"User statistics computed for {len(user_stats):,} users\")\n",
    "print(\"\\nUser features summary:\")\n",
    "print(user_stats.describe())\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for idx, col in enumerate(['user_rating_count', 'user_avg_rating', 'user_rating_std', \n",
    "                           'user_rating_min', 'user_rating_max']):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    user_stats[col].hist(bins=50, ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count')\n",
    "axes[1, 2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Movie Aggregation Features\n",
    "\n",
    "**Critical**: Computed ONLY from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute movie statistics from TRAIN ONLY\n",
    "movie_stats = train_ratings.groupby('movie_id')['rating'].agg([\n",
    "    ('movie_rating_count', 'count'),\n",
    "    ('movie_avg_rating', 'mean'),\n",
    "    ('movie_rating_std', 'std'),\n",
    "    ('movie_rating_min', 'min'),\n",
    "    ('movie_rating_max', 'max')\n",
    "]).reset_index()\n",
    "\n",
    "# Fill NaN std (happens when movie has only 1 rating)\n",
    "movie_stats['movie_rating_std'] = movie_stats['movie_rating_std'].fillna(0)\n",
    "\n",
    "print(f\"Movie statistics computed for {len(movie_stats):,} movies\")\n",
    "print(\"\\nMovie features summary:\")\n",
    "print(movie_stats.describe())\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "for idx, col in enumerate(['movie_rating_count', 'movie_avg_rating', 'movie_rating_std',\n",
    "                           'movie_rating_min', 'movie_rating_max']):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    movie_stats[col].hist(bins=50, ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count')\n",
    "axes[1, 2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cold-Start Defaults\n",
    "\n",
    "Define defaults for users/movies not seen in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global defaults from training data\n",
    "global_mean_rating = train_ratings['rating'].mean()\n",
    "global_std_rating = train_ratings['rating'].std()\n",
    "global_min_rating = train_ratings['rating'].min()\n",
    "global_max_rating = train_ratings['rating'].max()\n",
    "\n",
    "cold_start_defaults = {\n",
    "    'user_rating_count': 0,  # Flag as new user\n",
    "    'user_avg_rating': global_mean_rating,\n",
    "    'user_rating_std': global_std_rating,\n",
    "    'user_rating_min': global_min_rating,\n",
    "    'user_rating_max': global_max_rating,\n",
    "    'movie_rating_count': 0,  # Flag as new movie\n",
    "    'movie_avg_rating': global_mean_rating,\n",
    "    'movie_rating_std': global_std_rating,\n",
    "    'movie_rating_min': global_min_rating,\n",
    "    'movie_rating_max': global_max_rating\n",
    "}\n",
    "\n",
    "print(\"Cold-start defaults:\")\n",
    "for key, value in cold_start_defaults.items():\n",
    "    print(f\"  {key}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Genre Features\n",
    "\n",
    "Multi-hot encoding of 18 movie genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract all unique genres\nall_genres = set()\nfor genres_str in movies['genres']:\n    all_genres.update(genres_str.split('|'))\n\nall_genres = sorted(all_genres)\nprint(f\"Found {len(all_genres)} unique genres: {all_genres}\")\n\n# Create binary features for each genre\n# Clean genre names for column names (replace special chars)\nmovies_with_genres = movies.copy()\nfor genre in all_genres:\n    # Clean genre name for column name\n    genre_clean = genre.lower().replace('-', '_').replace(\"'\", '')\n    col_name = f'genre_{genre_clean}'\n    movies_with_genres[col_name] = movies_with_genres['genres'].str.contains(genre, regex=False).astype(int)\n\n# Get list of genre columns\ngenre_cols = [col for col in movies_with_genres.columns if col.startswith('genre_')]\nprint(f\"\\nCreated {len(genre_cols)} genre features: {genre_cols}\")\n\n# Show genre distribution\ngenre_counts = movies_with_genres[genre_cols].sum().sort_values(ascending=False)\nprint(\"\\nGenre distribution:\")\nprint(genre_counts)\n\n# Visualize\nplt.figure(figsize=(12, 6))\ngenre_counts.plot(kind='barh')\nplt.title('Movie Count by Genre')\nplt.xlabel('Number of Movies')\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demographic Features\n",
    "\n",
    "Encode user demographics for cold-start and diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode gender: M=1, F=0\n",
    "users_encoded = users.copy()\n",
    "users_encoded['gender'] = (users_encoded['gender'] == 'M').astype(int)\n",
    "\n",
    "# age and occupation are already numeric, keep as-is\n",
    "demographic_cols = ['gender', 'age', 'occupation']\n",
    "\n",
    "# Rename age to age_group for clarity\n",
    "users_encoded = users_encoded.rename(columns={'age': 'age_group'})\n",
    "\n",
    "print(\"Demographic features:\")\n",
    "print(f\"  gender: binary (M=1, F=0)\")\n",
    "print(f\"  age_group: {sorted(users_encoded['age_group'].unique())}\")\n",
    "print(f\"  occupation: {sorted(users_encoded['occupation'].unique())}\")\n",
    "\n",
    "print(\"\\nDemographic distributions:\")\n",
    "print(users_encoded[['gender', 'age_group', 'occupation']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Materialization Function\n",
    "\n",
    "Build features for any ratings dataframe (train/val/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(ratings_df, user_stats, movie_stats, movies_df, users_df, defaults):\n",
    "    \"\"\"\n",
    "    Build feature matrix for a ratings dataframe.\n",
    "    \n",
    "    Args:\n",
    "        ratings_df: Ratings to build features for\n",
    "        user_stats: Pre-computed user statistics (from train only)\n",
    "        movie_stats: Pre-computed movie statistics (from train only)\n",
    "        movies_df: Movie metadata with genre features\n",
    "        users_df: User demographics\n",
    "        defaults: Cold-start default values\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all features\n",
    "    \"\"\"\n",
    "    print(f\"Building features for {len(ratings_df):,} ratings...\")\n",
    "    \n",
    "    # Start with ratings\n",
    "    features = ratings_df.copy()\n",
    "    \n",
    "    # 1. Merge user features (left join to handle cold-start)\n",
    "    features = features.merge(user_stats, on='user_id', how='left')\n",
    "    \n",
    "    # 2. Merge movie features (left join)\n",
    "    features = features.merge(movie_stats, on='movie_id', how='left')\n",
    "    \n",
    "    # 3. Fill NaN with cold-start defaults\n",
    "    for col, default_val in defaults.items():\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].fillna(default_val)\n",
    "    \n",
    "    # 4. Merge demographics\n",
    "    features = features.merge(\n",
    "        users_df[['user_id', 'gender', 'age_group', 'occupation']], \n",
    "        on='user_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 5. Merge genres (keep only genre columns + movie_id for merge)\n",
    "    genre_features = movies_df[['movie_id'] + genre_cols]\n",
    "    features = features.merge(genre_features, on='movie_id', how='left')\n",
    "    \n",
    "    # 6. Compute interaction features\n",
    "    features['user_movie_rating_diff'] = features['user_avg_rating'] - features['movie_avg_rating']\n",
    "    features['user_rating_count_norm'] = np.log1p(features['user_rating_count'])\n",
    "    features['movie_rating_count_norm'] = np.log1p(features['movie_rating_count'])\n",
    "    features['user_movie_activity_product'] = features['user_rating_count_norm'] * features['movie_rating_count_norm']\n",
    "    \n",
    "    # 7. Verify no missing values\n",
    "    missing = features.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nWarning: Missing values found:\")\n",
    "        print(missing[missing > 0])\n",
    "        # Fill any remaining NaN with 0 (e.g., for genre features of new movies)\n",
    "        features = features.fillna(0)\n",
    "    \n",
    "    print(f\"Features built: {features.shape}\")\n",
    "    print(f\"Columns: {len(features.columns)}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Materialize Features for All Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features for train/val/test\n",
    "train_features = build_features(\n",
    "    train_ratings, user_stats, movie_stats, \n",
    "    movies_with_genres, users_encoded, cold_start_defaults\n",
    ")\n",
    "\n",
    "val_features = build_features(\n",
    "    val_ratings, user_stats, movie_stats,\n",
    "    movies_with_genres, users_encoded, cold_start_defaults\n",
    ")\n",
    "\n",
    "test_features = build_features(\n",
    "    test_ratings, user_stats, movie_stats,\n",
    "    movies_with_genres, users_encoded, cold_start_defaults\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Feature Materialization Complete\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train: {train_features.shape}\")\n",
    "print(f\"Val:   {val_features.shape}\")\n",
    "print(f\"Test:  {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Leakage Validation\n",
    "\n",
    "Verify no future information leaked into features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: User/movie stats should be identical across splits (frozen from train)\n",
    "print(\"Leakage Check 1: User stats consistency\")\n",
    "sample_user = train_features['user_id'].iloc[0]\n",
    "train_user_avg = train_features[train_features['user_id'] == sample_user]['user_avg_rating'].iloc[0]\n",
    "\n",
    "if sample_user in val_features['user_id'].values:\n",
    "    val_user_avg = val_features[val_features['user_id'] == sample_user]['user_avg_rating'].iloc[0]\n",
    "    print(f\"Sample user {sample_user}: train_avg={train_user_avg:.3f}, val_avg={val_user_avg:.3f}\")\n",
    "    assert abs(train_user_avg - val_user_avg) < 0.001, \"User stats differ between splits!\"\n",
    "    print(\"✓ User stats are consistent (frozen from train)\")\n",
    "else:\n",
    "    print(f\"Sample user {sample_user} not in val (as expected)\")\n",
    "\n",
    "# Check 2: Cold-start users should have default values\n",
    "print(\"\\nLeakage Check 2: Cold-start handling\")\n",
    "cold_start_users = val_features[val_features['user_rating_count'] == 0]\n",
    "print(f\"Cold-start users in val: {len(cold_start_users)}\")\n",
    "if len(cold_start_users) > 0:\n",
    "    print(\"Sample cold-start user features:\")\n",
    "    print(cold_start_users[['user_avg_rating', 'user_rating_std', 'user_rating_count']].head())\n",
    "else:\n",
    "    print(\"✓ No cold-start users in val (as expected with filtered splits)\")\n",
    "\n",
    "# Check 3: No NaN values\n",
    "print(\"\\nLeakage Check 3: No missing values\")\n",
    "for name, df in [(\"Train\", train_features), (\"Val\", val_features), (\"Test\", test_features)]:\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"{name}: {missing} missing values\")\n",
    "    assert missing == 0, f\"Found missing values in {name}\"\n",
    "print(\"✓ No missing values in any split\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ All leakage checks passed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: Feature distributions across splits\n",
    "print(\"Feature Distribution Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "key_features = ['user_rating_count', 'user_avg_rating', 'movie_rating_count', 'movie_avg_rating']\n",
    "\n",
    "for feature in key_features:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Train: mean={train_features[feature].mean():.2f}, std={train_features[feature].std():.2f}\")\n",
    "    print(f\"  Val:   mean={val_features[feature].mean():.2f}, std={val_features[feature].std():.2f}\")\n",
    "    print(f\"  Test:  mean={test_features[feature].mean():.2f}, std={test_features[feature].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 2: Correlation with target\n",
    "print(\"\\nFeature Correlation with Target (rating)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute correlations on train set\n",
    "feature_cols = [col for col in train_features.columns \n",
    "                if col not in ['user_id', 'movie_id', 'rating', 'timestamp', 'title', 'genres', 'zip_code']]\n",
    "\n",
    "correlations = train_features[feature_cols + ['rating']].corr()['rating'].drop('rating').sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 positive correlations:\")\n",
    "print(correlations.head(10))\n",
    "\n",
    "print(\"\\nTop 10 negative correlations:\")\n",
    "print(correlations.tail(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlations.sort_values().plot(kind='barh')\n",
    "plt.title('Feature Correlation with Rating')\n",
    "plt.xlabel('Correlation')\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 3: Feature correlation matrix (identify redundancy)\n",
    "print(\"\\nFeature Correlation Matrix (top features)\")\n",
    "\n",
    "# Select subset of features for visualization\n",
    "top_features = ['user_rating_count', 'user_avg_rating', 'user_rating_std',\n",
    "                'movie_rating_count', 'movie_avg_rating', 'movie_rating_std',\n",
    "                'user_movie_rating_diff', 'user_rating_count_norm', 'movie_rating_count_norm',\n",
    "                'gender', 'age_group', 'occupation']\n",
    "\n",
    "corr_matrix = train_features[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs (>0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "if high_corr:\n",
    "    print(\"\\nHighly correlated feature pairs (|r| > 0.9):\")\n",
    "    for feat1, feat2, corr in high_corr:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"\\n✓ No highly correlated features (|r| > 0.9)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet\n",
    "print(\"Saving features...\")\n",
    "\n",
    "train_features.to_parquet(FEATURES_DIR / 'train_features.parquet', index=False)\n",
    "val_features.to_parquet(FEATURES_DIR / 'val_features.parquet', index=False)\n",
    "test_features.to_parquet(FEATURES_DIR / 'test_features.parquet', index=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "for file in sorted(FEATURES_DIR.glob('*.parquet')):\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {file.name:30} ({size_mb:6.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature metadata\n",
    "metadata = {\n",
    "    \"version\": \"1.0\",\n",
    "    \"created_at\": pd.Timestamp.now().isoformat(),\n",
    "    \"train_timestamp_max\": int(train_ratings['timestamp'].max()),\n",
    "    \"num_features\": len(feature_cols),\n",
    "    \"feature_groups\": {\n",
    "        \"user_agg\": list(FEATURE_SCHEMA[\"user_aggregations\"].keys()),\n",
    "        \"movie_agg\": list(FEATURE_SCHEMA[\"movie_aggregations\"].keys()),\n",
    "        \"interaction\": list(FEATURE_SCHEMA[\"interactions\"].keys()),\n",
    "        \"demographic\": list(FEATURE_SCHEMA[\"demographics\"].keys()),\n",
    "        \"genre\": genre_cols\n",
    "    },\n",
    "    \"cold_start_defaults\": {k: float(v) for k, v in cold_start_defaults.items()},\n",
    "    \"split_sizes\": {\n",
    "        \"train\": len(train_features),\n",
    "        \"val\": len(val_features),\n",
    "        \"test\": len(test_features)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(FEATURES_DIR / 'feature_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Metadata saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save README\n",
    "readme_content = f\"\"\"# Ranking Model Features\n",
    "\n",
    "## Feature Set v1.0\n",
    "\n",
    "Created: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Files\n",
    "\n",
    "- `train_features.parquet`: Training features ({len(train_features):,} rows)\n",
    "- `val_features.parquet`: Validation features ({len(val_features):,} rows)\n",
    "- `test_features.parquet`: Test features ({len(test_features):,} rows)\n",
    "- `feature_metadata.json`: Feature schema and metadata\n",
    "\n",
    "## Feature Categories ({len(feature_cols)} features total)\n",
    "\n",
    "### User Aggregation Features (5)\n",
    "Computed from training data only:\n",
    "- user_rating_count: Number of ratings given\n",
    "- user_avg_rating: Mean rating given\n",
    "- user_rating_std: Std dev of ratings\n",
    "- user_rating_min: Minimum rating\n",
    "- user_rating_max: Maximum rating\n",
    "\n",
    "### Movie Aggregation Features (5)\n",
    "Computed from training data only:\n",
    "- movie_rating_count: Number of ratings received (popularity)\n",
    "- movie_avg_rating: Mean rating received (quality)\n",
    "- movie_rating_std: Std dev (polarization)\n",
    "- movie_rating_min: Minimum rating\n",
    "- movie_rating_max: Maximum rating\n",
    "\n",
    "### User-Movie Interaction Features (4)\n",
    "- user_movie_rating_diff: user_avg - movie_avg\n",
    "- user_rating_count_norm: log1p(user_rating_count)\n",
    "- movie_rating_count_norm: log1p(movie_rating_count)\n",
    "- user_movie_activity_product: user_norm * movie_norm\n",
    "\n",
    "### Demographic Features (3)\n",
    "- gender: Binary (M=1, F=0)\n",
    "- age_group: 7 age bins (1, 18, 25, 35, 45, 50, 56)\n",
    "- occupation: 21 occupation codes (0-20)\n",
    "\n",
    "### Genre Features ({len(genre_cols)})\n",
    "Multi-hot encoding of movie genres:\n",
    "{', '.join(genre_cols)}\n",
    "\n",
    "## Data Leakage Prevention\n",
    "\n",
    "- User/movie aggregations computed **only from training data**\n",
    "- Same statistics applied to val/test (frozen at train time)\n",
    "- Cold-start users/movies receive global defaults\n",
    "- No future information used in feature computation\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load features\n",
    "train = pd.read_parquet('train_features.parquet')\n",
    "val = pd.read_parquet('val_features.parquet')\n",
    "test = pd.read_parquet('test_features.parquet')\n",
    "\n",
    "# Separate features and target\n",
    "feature_cols = [col for col in train.columns if col not in ['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['rating']\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "with open(FEATURES_DIR / 'README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"✓ README saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "Features successfully created and saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  User aggregations:     5\")\n",
    "print(f\"  Movie aggregations:    5\")\n",
    "print(f\"  Interactions:          4\")\n",
    "print(f\"  Demographics:          3\")\n",
    "print(f\"  Genres:               {len(genre_cols)}\")\n",
    "print(f\"\\nDatasets:\")\n",
    "print(f\"  Train: {train_features.shape}\")\n",
    "print(f\"  Val:   {val_features.shape}\")\n",
    "print(f\"  Test:  {test_features.shape}\")\n",
    "print(f\"\\nFiles saved to: {FEATURES_DIR}\")\n",
    "print(f\"\\nNext step: Train GBDT ranking model using these features!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}